{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un detector de imágenes muy sencillo utilizando correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=list()\n",
    "a.append([\n",
    "    [0,0,0,1,1,0,0,0],\n",
    "    [0,0,1,1,1,1,0,0],\n",
    "    [0,1,1,0,0,1,1,0],\n",
    "    [0,1,1,0,0,1,1,0],\n",
    "    [0,1,1,1,1,1,1,0],\n",
    "    [0,1,1,0,0,1,1,0],\n",
    "    [0,1,1,0,0,1,1,0],\n",
    "    [0,1,1,0,0,1,1,0]])\n",
    "\n",
    "a.append([\n",
    "    [1,1,0,0,0,0,0,0],\n",
    "    [1,1,0,0,0,0,0,0],\n",
    "    [1,1,0,0,0,0,0,0],\n",
    "    [1,1,0,0,0,0,0,0],\n",
    "    [1,1,0,0,0,0,0,0],\n",
    "    [1,1,0,0,0,0,0,0],\n",
    "    [1,1,1,1,1,1,1,0],\n",
    "    [1,1,1,1,1,1,1,0]])\n",
    "\n",
    "a.append([\n",
    "    [1,1,1,1,1,1,1,1],\n",
    "    [1,1,1,1,1,1,1,1],\n",
    "    [0,0,0,1,1,0,0,0],\n",
    "    [0,0,0,1,1,0,0,0],\n",
    "    [0,0,0,1,1,0,0,0],\n",
    "    [0,0,0,1,1,0,0,0],\n",
    "    [0,0,0,1,1,0,0,0],\n",
    "    [0,0,0,1,1,0,0,0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "a=np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos=list()\n",
    "labels=list()\n",
    "ruido=1\n",
    "size=1024\n",
    "indices=[0,1,2]\n",
    "for idx in range(size):\n",
    "    l1=random.choice(indices)\n",
    "    l2=random.choice(indices)\n",
    "    l3=random.choice(indices)\n",
    "    textos.append(np.hstack([a[l1],a[l2],a[l3]])+np.random.rand(8,24)*ruido)\n",
    "    label=[np.zeros(3),np.zeros(3),np.zeros(3)]\n",
    "    label[0][l1]=1\n",
    "    label[1][l2]=1\n",
    "    label[2][l3]=1\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizamos los datos g\n",
    "import matplotlib.pylab as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_aspect('equal')\n",
    "plt.imshow(textos[32], cmap=plt.cm.ocean)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1., 0., 0.]), array([0., 0., 1.]), array([0., 1., 0.])]\n"
     ]
    }
   ],
   "source": [
    "import scipy.signal as ss\n",
    "corr=ss.correlate2d(textos[32],a[2])\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_aspect('equal')\n",
    "plt.imshow(corr, cmap=plt.cm.ocean)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(labels[32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=list()\n",
    "test=list()\n",
    "train_labels=np.array(labels[0:924])\n",
    "test_labels=np.array(labels[924:])\n",
    "for texto in textos[0:924]:\n",
    "    corr=np.hstack([ss.correlate2d(texto,a[0]),ss.correlate2d(texto,a[1]),ss.correlate2d(texto,a[2])])\n",
    "    corr=corr.reshape([1,1395])[0]\n",
    "    train.append(corr)\n",
    "for texto in textos[924:]:\n",
    "    corr=np.hstack([ss.correlate2d(texto,a[0]),ss.correlate2d(texto,a[1]),ss.correlate2d(texto,a[2])])\n",
    "    corr=corr.reshape([1,1395])[0]\n",
    "    test.append(corr)\n",
    "train=np.array(train)\n",
    "test=np.array(test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ejemplo con Lena:\n",
    "\n",
    "https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.signal.correlate2d.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cselmo/anaconda3/envs/OpLaDyn/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import shutil\n",
    "from tensorboard import summary as summary_lib\n",
    "logs_path=\"logdir\"\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 200\n",
    "batch_size = 256\n",
    "display_step = 1\n",
    "hidden_units=50\n",
    "\n",
    "# Network Parameters\n",
    "n_input =  train.shape[1] # Vocab size \n",
    "n_classes = 3 # Twenty news groups # classes\n",
    "\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    # tf Graph input\n",
    "    X = tf.placeholder(\"float\", [None, n_input],name=\"X\")\n",
    "with tf.name_scope(\"labels\"):\n",
    "    YL1 = tf.placeholder(\"float\", [None, n_classes],name=\"YL1\")\n",
    "    YL2 = tf.placeholder(\"float\", [None, n_classes],name=\"YL2\")\n",
    "    YL3 = tf.placeholder(\"float\", [None, n_classes],name=\"YL3\")\n",
    "\n",
    "# Construct model\n",
    "with tf.name_scope('Capa1'):\n",
    "    # Model\n",
    "    weights1= tf.Variable(tf.random_normal([n_input, hidden_units]),name=\"weights1\")\n",
    "    bias1= tf.Variable(tf.random_normal([hidden_units]),name=\"bias1\")\n",
    "    act1= tf.nn.sigmoid(tf.matmul(X,weights1)+bias1, name=\"activacion_1\")\n",
    "\n",
    "with tf.name_scope('Letra1'):\n",
    "    # Model\n",
    "    weightsL1= tf.Variable(tf.random_normal([hidden_units, n_classes]),name=\"weightsL1\")\n",
    "    biasL1= tf.Variable(tf.random_normal([n_classes]),name=\"biasL1\")\n",
    "    logitsL1= tf.matmul(act1,weightsL1)+biasL1\n",
    "\n",
    "with tf.name_scope('Letra2'):\n",
    "    # Model\n",
    "    weightsL2= tf.Variable(tf.random_normal([hidden_units, n_classes]),name=\"weightsL2\")\n",
    "    biasL2= tf.Variable(tf.random_normal([n_classes]),name=\"biasL2\")\n",
    "    logitsL2= tf.matmul(act1,weightsL2)+biasL2\n",
    "\n",
    "with tf.name_scope('Letra3'):\n",
    "    # Model\n",
    "    weightsL3= tf.Variable(tf.random_normal([hidden_units, n_classes]),name=\"weightsL3\")\n",
    "    biasL3= tf.Variable(tf.random_normal([n_classes]),name=\"biasL3\")\n",
    "    logitsL3= tf.matmul(act1,weightsL3)+biasL3\n",
    "\n",
    "with tf.name_scope('Loss'):\n",
    "# Define loss and optimizer\n",
    "    L1cost=tf.nn.softmax_cross_entropy_with_logits_v2(logits=logitsL1, labels=YL1)\n",
    "    L2cost=tf.nn.softmax_cross_entropy_with_logits_v2(logits=logitsL2, labels=YL2)\n",
    "    L3cost=tf.nn.softmax_cross_entropy_with_logits_v2(logits=logitsL3, labels=YL3)\n",
    "    loss_op = tf.reduce_mean(L1cost+L2cost+L3cost,name=\"costo\")\n",
    "with tf.name_scope('BGD'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,name=\"optimizador\")\n",
    "    train_op = optimizer.minimize(loss_op)\n",
    "with tf.name_scope('Accuracy'):\n",
    "    # Accuracy\n",
    "    #pred = tf.nn.softmax(logits) # Softmax\n",
    "    acc_op = tf.concat([tf.equal(tf.argmax(logitsL1, 1), tf.argmax(YL1, 1)),tf.equal(tf.argmax(logitsL2, 1), tf.argmax(YL2, 1)),\n",
    "                        tf.equal(tf.argmax(logitsL3, 1), tf.argmax(YL3, 1))],0)\n",
    "    acc_op = tf.reduce_mean(tf.cast(acc_op, tf.float32),name=\"acc_red_mean\")\n",
    "    \n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "# Create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"loss\", loss_op)\n",
    "# Create a summary to monitor accuracy tensor\n",
    "tf.summary.scalar(\"accuracy\", acc_op)\n",
    "# Merge all summaries into a single op\n",
    "tf.summary.histogram('histogram', weights1)\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost=13.510557175\n",
      "Epoch: 0002 cost=9.262794495\n",
      "Epoch: 0003 cost=6.666718006\n",
      "Epoch: 0004 cost=5.488290310\n",
      "Epoch: 0005 cost=4.631754398\n",
      "Epoch: 0006 cost=3.942278147\n",
      "Epoch: 0007 cost=3.987541437\n",
      "Epoch: 0008 cost=3.919039726\n",
      "Epoch: 0009 cost=3.663575649\n",
      "Epoch: 0010 cost=3.372605562\n",
      "Epoch: 0011 cost=3.017538548\n",
      "Epoch: 0012 cost=2.701761723\n",
      "Epoch: 0013 cost=2.661704540\n",
      "Epoch: 0014 cost=2.690126896\n",
      "Epoch: 0015 cost=2.767950296\n",
      "Epoch: 0016 cost=2.759010553\n",
      "Epoch: 0017 cost=2.736645222\n",
      "Epoch: 0018 cost=2.701277256\n",
      "Epoch: 0019 cost=2.618887424\n",
      "Epoch: 0020 cost=2.542824268\n",
      "Epoch: 0021 cost=2.512465000\n",
      "Epoch: 0022 cost=2.489504337\n",
      "Epoch: 0023 cost=2.378221750\n",
      "Epoch: 0024 cost=2.327602863\n",
      "Epoch: 0025 cost=2.291867495\n",
      "Epoch: 0026 cost=2.293885708\n",
      "Epoch: 0027 cost=2.318919897\n",
      "Epoch: 0028 cost=2.290647268\n",
      "Epoch: 0029 cost=2.224610329\n",
      "Epoch: 0030 cost=2.169621944\n",
      "Epoch: 0031 cost=2.112930059\n",
      "Epoch: 0032 cost=2.121603489\n",
      "Epoch: 0033 cost=2.157269478\n",
      "Epoch: 0034 cost=2.152311325\n",
      "Epoch: 0035 cost=2.095755577\n",
      "Epoch: 0036 cost=2.049711227\n",
      "Epoch: 0037 cost=2.023099661\n",
      "Epoch: 0038 cost=2.010879993\n",
      "Epoch: 0039 cost=1.999533176\n",
      "Epoch: 0040 cost=1.945867419\n",
      "Epoch: 0041 cost=1.889991045\n",
      "Epoch: 0042 cost=1.898129463\n",
      "Epoch: 0043 cost=1.886446357\n",
      "Epoch: 0044 cost=1.852686524\n",
      "Epoch: 0045 cost=1.812505603\n",
      "Epoch: 0046 cost=1.789339423\n",
      "Epoch: 0047 cost=1.769498348\n",
      "Epoch: 0048 cost=1.774958372\n",
      "Epoch: 0049 cost=1.761133790\n",
      "Epoch: 0050 cost=1.752245665\n",
      "Epoch: 0051 cost=1.728348494\n",
      "Epoch: 0052 cost=1.708517551\n",
      "Epoch: 0053 cost=1.698390722\n",
      "Epoch: 0054 cost=1.694949508\n",
      "Epoch: 0055 cost=1.680905342\n",
      "Epoch: 0056 cost=1.666345358\n",
      "Epoch: 0057 cost=1.650371313\n",
      "Epoch: 0058 cost=1.635060310\n",
      "Epoch: 0059 cost=1.632622480\n",
      "Epoch: 0060 cost=1.636340141\n",
      "Epoch: 0061 cost=1.618786573\n",
      "Epoch: 0062 cost=1.602671146\n",
      "Epoch: 0063 cost=1.595414281\n",
      "Epoch: 0064 cost=1.580972791\n",
      "Epoch: 0065 cost=1.577823043\n",
      "Epoch: 0066 cost=1.579601049\n",
      "Epoch: 0067 cost=1.568419933\n",
      "Epoch: 0068 cost=1.552217603\n",
      "Epoch: 0069 cost=1.550906539\n",
      "Epoch: 0070 cost=1.553768158\n",
      "Epoch: 0071 cost=1.560192347\n",
      "Epoch: 0072 cost=1.528415322\n",
      "Epoch: 0073 cost=1.521516919\n",
      "Epoch: 0074 cost=1.519704938\n",
      "Epoch: 0075 cost=1.506359100\n",
      "Epoch: 0076 cost=1.514029145\n",
      "Epoch: 0077 cost=1.527430177\n",
      "Epoch: 0078 cost=1.505741954\n",
      "Epoch: 0079 cost=1.484606147\n",
      "Epoch: 0080 cost=1.473553777\n",
      "Epoch: 0081 cost=1.485111117\n",
      "Epoch: 0082 cost=1.491872549\n",
      "Epoch: 0083 cost=1.477935553\n",
      "Epoch: 0084 cost=1.477063060\n",
      "Epoch: 0085 cost=1.473656416\n",
      "Epoch: 0086 cost=1.460076451\n",
      "Epoch: 0087 cost=1.450194836\n",
      "Epoch: 0088 cost=1.450892210\n",
      "Epoch: 0089 cost=1.436787009\n",
      "Epoch: 0090 cost=1.442444563\n",
      "Epoch: 0091 cost=1.451308489\n",
      "Epoch: 0092 cost=1.451919317\n",
      "Epoch: 0093 cost=1.428511143\n",
      "Epoch: 0094 cost=1.400773048\n",
      "Epoch: 0095 cost=1.400824428\n",
      "Epoch: 0096 cost=1.405029297\n",
      "Epoch: 0097 cost=1.397828460\n",
      "Epoch: 0098 cost=1.378587604\n",
      "Epoch: 0099 cost=1.383832693\n",
      "Epoch: 0100 cost=1.378578305\n",
      "Epoch: 0101 cost=1.376194596\n",
      "Epoch: 0102 cost=1.366633177\n",
      "Epoch: 0103 cost=1.347656131\n",
      "Epoch: 0104 cost=1.338672638\n",
      "Epoch: 0105 cost=1.344164491\n",
      "Epoch: 0106 cost=1.337806821\n",
      "Epoch: 0107 cost=1.329048753\n",
      "Epoch: 0108 cost=1.312178135\n",
      "Epoch: 0109 cost=1.310316443\n",
      "Epoch: 0110 cost=1.322269440\n",
      "Epoch: 0111 cost=1.321408272\n",
      "Epoch: 0112 cost=1.307181716\n",
      "Epoch: 0113 cost=1.287986279\n",
      "Epoch: 0114 cost=1.271150112\n",
      "Epoch: 0115 cost=1.268008590\n",
      "Epoch: 0116 cost=1.263134360\n",
      "Epoch: 0117 cost=1.260149598\n",
      "Epoch: 0118 cost=1.253978252\n",
      "Epoch: 0119 cost=1.238970518\n",
      "Epoch: 0120 cost=1.228288412\n",
      "Epoch: 0121 cost=1.225797892\n",
      "Epoch: 0122 cost=1.221908450\n",
      "Epoch: 0123 cost=1.222362757\n",
      "Epoch: 0124 cost=1.212533712\n",
      "Epoch: 0125 cost=1.210792303\n",
      "Epoch: 0126 cost=1.197227716\n",
      "Epoch: 0127 cost=1.183385015\n",
      "Epoch: 0128 cost=1.185279012\n",
      "Epoch: 0129 cost=1.186714172\n",
      "Epoch: 0130 cost=1.188564658\n",
      "Epoch: 0131 cost=1.192700744\n",
      "Epoch: 0132 cost=1.174263120\n",
      "Epoch: 0133 cost=1.153600931\n",
      "Epoch: 0134 cost=1.146723509\n",
      "Epoch: 0135 cost=1.159941912\n",
      "Epoch: 0136 cost=1.157292843\n",
      "Epoch: 0137 cost=1.137194037\n",
      "Epoch: 0138 cost=1.117455721\n",
      "Epoch: 0139 cost=1.115097642\n",
      "Epoch: 0140 cost=1.125088573\n",
      "Epoch: 0141 cost=1.116525054\n",
      "Epoch: 0142 cost=1.097162127\n",
      "Epoch: 0143 cost=1.101075649\n",
      "Epoch: 0144 cost=1.100178838\n",
      "Epoch: 0145 cost=1.080526114\n",
      "Epoch: 0146 cost=1.070297241\n",
      "Epoch: 0147 cost=1.069452882\n",
      "Epoch: 0148 cost=1.064005494\n",
      "Epoch: 0149 cost=1.052371383\n",
      "Epoch: 0150 cost=1.047559142\n",
      "Epoch: 0151 cost=1.040084839\n",
      "Epoch: 0152 cost=1.027965546\n",
      "Epoch: 0153 cost=1.013593674\n",
      "Epoch: 0154 cost=1.013585687\n",
      "Epoch: 0155 cost=1.018551707\n",
      "Epoch: 0156 cost=0.991796732\n",
      "Epoch: 0157 cost=0.982353866\n",
      "Epoch: 0158 cost=0.988315284\n",
      "Epoch: 0159 cost=0.986785948\n",
      "Epoch: 0160 cost=0.986092985\n",
      "Epoch: 0161 cost=0.961279809\n",
      "Epoch: 0162 cost=0.948596239\n",
      "Epoch: 0163 cost=0.944778383\n",
      "Epoch: 0164 cost=0.931179941\n",
      "Epoch: 0165 cost=0.924963593\n",
      "Epoch: 0166 cost=0.912907124\n",
      "Epoch: 0167 cost=0.904785931\n",
      "Epoch: 0168 cost=0.894685268\n",
      "Epoch: 0169 cost=0.885022819\n",
      "Epoch: 0170 cost=0.876900256\n",
      "Epoch: 0171 cost=0.870033443\n",
      "Epoch: 0172 cost=0.857778430\n",
      "Epoch: 0173 cost=0.855370224\n",
      "Epoch: 0174 cost=0.845986545\n",
      "Epoch: 0175 cost=0.836154401\n",
      "Epoch: 0176 cost=0.832451999\n",
      "Epoch: 0177 cost=0.827214122\n",
      "Epoch: 0178 cost=0.820636153\n",
      "Epoch: 0179 cost=0.817334414\n",
      "Epoch: 0180 cost=0.819769740\n",
      "Epoch: 0181 cost=0.811198950\n",
      "Epoch: 0182 cost=0.797666788\n",
      "Epoch: 0183 cost=0.793530464\n",
      "Epoch: 0184 cost=0.807301164\n",
      "Epoch: 0185 cost=0.781925619\n",
      "Epoch: 0186 cost=0.770652473\n",
      "Epoch: 0187 cost=0.770811260\n",
      "Epoch: 0188 cost=0.759040475\n",
      "Epoch: 0189 cost=0.758134246\n",
      "Epoch: 0190 cost=0.779272854\n",
      "Epoch: 0191 cost=0.776615202\n",
      "Epoch: 0192 cost=0.765043855\n",
      "Epoch: 0193 cost=0.737310350\n",
      "Epoch: 0194 cost=0.727008045\n",
      "Epoch: 0195 cost=0.734848976\n",
      "Epoch: 0196 cost=0.738228142\n",
      "Epoch: 0197 cost=0.725813746\n",
      "Epoch: 0198 cost=0.707527995\n",
      "Epoch: 0199 cost=0.700935125\n",
      "Epoch: 0200 cost=0.702463150\n",
      "Optimization Finished!\n",
      "Accuracy: 0.97333336\n",
      "[2 2 0 0 0 1 0 0 0 2 1 0 0 2 2 2 0 2 1 0 0 0 2 0 2 1 2 2 0 2 1 1 0 0 2 0 1\n",
      " 0 1 1 2 0 2 0 2 0 0 2 2 1 0 2 2 2 0 1 2 0 1 0 1 2 1 2 2 1 1 1 2 2 1 2 1 1\n",
      " 2 1 0 0 1 0 0 2 2 2 0 1 1 0 2 0 0 0 0 0 1 2 0 2 2 1 0 0 1 2 2 0 0 2 1 2 1\n",
      " 1 0 2 1 0 0 1 2 0 0 1 0 1 2 0 1 0 1 0 0 0 0 0 2 2 2 1 0 1 2 2 0 2 1 0 0 2\n",
      " 0 1 0 2 2 1 1 0 0 1 0 0 1 1 0 1 0 0 1 0 0 2 1 0 1 0 1 1 2 1 0 1 0 1 0 2 0\n",
      " 0 1 2 1 1 2 0 1 2 0 1 2 0 1 1 0 1 1 1 1 1 1 2 1 0 0 1 1 1 1 0 0 1 1 2 2 1\n",
      " 2 2 2 2 0 2 1 0 2 0 2 0 1 0 1 2 1 0 1 1 2 0 0 0 2 2 2 2 0 1 0 1 2 0 1 1 2\n",
      " 2 2 2 2 1 0 1 0 0 0 2 0 2 2 0 2 2 2 2 1 1 2 2 2 0 1 2 0 2 1 1 0 1 2 1 1 0\n",
      " 0 1 1 2]\n",
      "[2 2 0 0 0 1 0 0 0 2 1 0 0 2 2 2 0 2 1 0 0 0 2 0 2 1 2 2 0 2 1 1 0 0 2 0 1\n",
      " 0 1 1 2 0 2 0 2 0 0 2 2 1 0 2 2 2 0 1 2 0 1 0 1 2 1 2 2 1 1 1 2 2 1 2 1 1\n",
      " 2 1 0 0 1 0 0 2 2 2 0 1 1 0 2 0 0 0 0 0 1 2 0 2 2 1 0 0 1 2 2 0 0 2 1 2 1\n",
      " 1 0 2 1 0 0 1 2 0 0 1 0 1 2 2 1 0 1 0 2 0 0 0 2 2 2 1 0 1 2 2 0 2 1 0 0 2\n",
      " 0 1 0 2 2 1 1 0 0 1 0 0 1 1 2 1 0 0 1 0 0 2 1 0 1 0 1 1 0 1 0 1 0 1 0 2 0\n",
      " 0 1 2 1 1 2 0 1 2 0 1 2 0 1 1 0 1 1 1 1 1 1 2 1 0 0 1 1 1 1 0 0 1 1 2 2 1\n",
      " 2 0 2 2 0 2 1 0 2 0 2 0 1 0 1 0 1 0 1 1 2 0 0 0 2 2 2 2 0 1 0 1 2 0 1 1 2\n",
      " 2 2 2 2 1 0 1 0 0 0 2 0 2 0 0 2 2 2 0 1 1 2 2 2 0 1 2 0 2 1 1 0 1 2 1 1 0\n",
      " 0 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # op to write logs to Tensorboard\n",
    "    summary_writer = tf.summary.FileWriter(logs_path, graph=sess.graph)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = 1\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            #batch_x, batch_y = next_batch(batch_size,X_train_data,labels)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c= sess.run([train_op, loss_op], feed_dict={X: train, \n",
    "                                                           YL1: train_labels[:,0], \n",
    "                                                           YL2: train_labels[:,1], \n",
    "                                                           YL3: train_labels[:,2]})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            summary, _,_ = sess.run([merged_summary_op,loss_op,acc_op],\n",
    "                                  feed_dict={X: test, \n",
    "                                             YL1: test_labels[:,0], \n",
    "                                             YL2: test_labels[:,1], \n",
    "                                             YL3: test_labels[:,2]})\n",
    "            summary_writer.add_summary(summary, epoch)\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(avg_cost))\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    pred = tf.concat([tf.argmax(logitsL1, 1), tf.argmax(logitsL2, 1), tf.argmax(logitsL3, 1)],0)\n",
    "    truth = tf.concat([tf.argmax(YL1, 1), tf.argmax(YL2, 1), tf.argmax(YL3, 1)],0)\n",
    "    accuracy = tf.equal(pred,truth)\n",
    "    accuracy= tf.reduce_mean(tf.cast(acc_op, tf.float32))\n",
    "\n",
    "    print(\"Accuracy:\", accuracy.eval({X: test, \n",
    "                                             YL1: test_labels[:,0], \n",
    "                                             YL2: test_labels[:,1], \n",
    "                                             YL3: test_labels[:,2]})) \n",
    "    print(pred.eval({X: test, \n",
    "                                             YL1: test_labels[:,0], \n",
    "                                             YL2: test_labels[:,1], \n",
    "                                             YL3: test_labels[:,2]}))\n",
    "    print(truth.eval({X: test, \n",
    "                                             YL1: test_labels[:,0], \n",
    "                                             YL2: test_labels[:,1], \n",
    "                                             YL3: test_labels[:,2]}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (OpLaDyn)",
   "language": "python",
   "name": "opladyn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
